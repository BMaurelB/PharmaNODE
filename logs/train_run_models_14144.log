/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib
  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so
  Reason: tried: '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py
run_models.py --niters 5000 -n 200 -s 40 -l 10 --dataset PK_Tacro --latent-ode --noise-weight 0.01 --max-t 5. --seed 2 --experiment 14144
Experiment 14144
Epoch 0010 [Test seq (cond on sampled tp)] | Loss 1299.085815 | Likelihood -1511.557983 | KL fp 3.2636 | FP STD 0.6583|
KL coef: 0.0
Train loss (one batch): 1783.483642578125
Train CE loss (one batch): 0.0
Test MSE (raw): 0.3030
Test MSE (smoothed with alpha=0.01): 0.3030
New best smoothed test MSE: 0.3030. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.3070
Test MSE group_1: 0.3002
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.3725
train MSE group_1: 0.3508
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0020 [Test seq (cond on sampled tp)] | Loss 1006.849365 | Likelihood -1089.348267 | KL fp 3.7789 | FP STD 0.4776|
KL coef: 0.09561792499119559
Train loss (one batch): 1166.67822265625
Train CE loss (one batch): 0.0
Test MSE (raw): 0.2186
Test MSE (smoothed with alpha=0.01): 0.3022
New best smoothed test MSE: 0.3022. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.2199
Test MSE group_1: 0.2177
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.2185
train MSE group_1: 0.2578
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0030 [Test seq (cond on sampled tp)] | Loss 776.542847 | Likelihood -833.148926 | KL fp 4.6398 | FP STD 0.2073|
KL coef: 0.18209306240276923
Train loss (one batch): 894.8230590820312
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1674
Test MSE (smoothed with alpha=0.01): 0.3009
New best smoothed test MSE: 0.3009. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.1786
Test MSE group_1: 0.1591
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1796
train MSE group_1: 0.1907
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0040 [Test seq (cond on sampled tp)] | Loss 547.470215 | Likelihood -581.509460 | KL fp 4.1869 | FP STD 0.2519|
KL coef: 0.2602996266117198
Train loss (one batch): 583.2024536132812
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1170
Test MSE (smoothed with alpha=0.01): 0.2990
New best smoothed test MSE: 0.2990. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.1347
Test MSE group_1: 0.1040
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1299
train MSE group_1: 0.1051
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0050 [Test seq (cond on sampled tp)] | Loss 413.800873 | Likelihood -421.713226 | KL fp 4.3827 | FP STD 0.2059|
KL coef: 0.3310282414303197
Train loss (one batch): 392.2449645996094
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0851
Test MSE (smoothed with alpha=0.01): 0.2969
New best smoothed test MSE: 0.2969. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.1000
Test MSE group_1: 0.0741
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0713
train MSE group_1: 0.0903
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0060 [Test seq (cond on sampled tp)] | Loss 318.440369 | Likelihood -322.833069 | KL fp 4.7793 | FP STD 0.1722|
KL coef: 0.39499393286246365
Train loss (one batch): 303.85467529296875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0653
Test MSE (smoothed with alpha=0.01): 0.2946
New best smoothed test MSE: 0.2946. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0646
Test MSE group_1: 0.0658
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0533
train MSE group_1: 0.0719
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0070 [Test seq (cond on sampled tp)] | Loss 273.747803 | Likelihood -279.321289 | KL fp 4.6973 | FP STD 0.1592|
KL coef: 0.4528433576092388
Train loss (one batch): 270.89031982421875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0566
Test MSE (smoothed with alpha=0.01): 0.2922
New best smoothed test MSE: 0.2922. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0465
Test MSE group_1: 0.0641
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0460
train MSE group_1: 0.0652
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0080 [Test seq (cond on sampled tp)] | Loss 268.152405 | Likelihood -273.873993 | KL fp 4.7180 | FP STD 0.1856|
KL coef: 0.505161340399793
Train loss (one batch): 254.2489013671875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0555
Test MSE (smoothed with alpha=0.01): 0.2898
New best smoothed test MSE: 0.2898. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0419
Test MSE group_1: 0.0655
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0403
train MSE group_1: 0.0657
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0090 [Test seq (cond on sampled tp)] | Loss 262.650574 | Likelihood -269.471924 | KL fp 4.7306 | FP STD 0.1850|
KL coef: 0.5524767862361895
Train loss (one batch): 245.40675354003906
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0546
Test MSE (smoothed with alpha=0.01): 0.2875
New best smoothed test MSE: 0.2875. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0406
Test MSE group_1: 0.0650
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0374
train MSE group_1: 0.0654
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0100 [Test seq (cond on sampled tp)] | Loss 254.914185 | Likelihood -258.717224 | KL fp 4.8169 | FP STD 0.1644|
KL coef: 0.5952680273216762
Train loss (one batch): 237.15921020507812
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0525
Test MSE (smoothed with alpha=0.01): 0.2851
New best smoothed test MSE: 0.2851. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0393
Test MSE group_1: 0.0622
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0354
train MSE group_1: 0.0642
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14144
Epoch 0110 [Test seq (cond on sampled tp)] | Loss 251.798782 | Likelihood -253.014801 | KL fp 4.9793 | FP STD 0.1432|
KL coef: 0.6339676587267709
Train loss (one batch): 237.26199340820312
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0513
Test MSE (smoothed with alpha=0.01): 0.2828
New best smoothed test MSE: 0.2828. Saving best model to experiments/experiment_14144_best.ckpt
Test MSE group_0: 0.0379
Test MSE group_1: 0.0612
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0348
train MSE group_1: 0.0636
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Couldn't import umap
Sampling dataset of 200 training examples
############## ['159', '160', '161', '162', '163', '165', '166', '168', '171', '172', '173', '174', '175', '177', '178', '179', '180', '181', '182', '183', '185', '186', '188', '189', '190', '191', '192', '193', '195', '196', '198', '199', '200']
163
TensorBoard logs will be saved to: experiments/runs/14144
Traceback (most recent call last):
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py", line 288, in <module>
    train_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/base_models.py", line 325, in compute_all_losses
    rec_likelihood = self.get_gaussian_likelihood(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/base_models.py", line 227, in get_gaussian_likelihood
    log_density_data = masked_gaussian_log_density(pred_y, truth_repeated, 
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/likelihood_eval.py", line 193, in masked_gaussian_log_density
    res = compute_masked_likelihood(mu, data, mask, func)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/likelihood_eval.py", line 153, in compute_masked_likelihood
    log_prob = likelihood_func(mu_masked, data_masked, indices = (i,k,j))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/likelihood_eval.py", line 192, in <lambda>
    func = lambda mu, data, indices: gaussian_log_likelihood(mu, data, obsrv_std = obsrv_std, indices = indices)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/likelihood_eval.py", line 30, in gaussian_log_likelihood
    log_prob = gaussian.log_prob(data_2d) 
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/distributions/independent.py", line 111, in log_prob
    return _sum_rightmost(log_prob, self.reinterpreted_batch_ndims)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/distributions/utils.py", line 68, in _sum_rightmost
    def _sum_rightmost(value, dim):
    
KeyboardInterrupt
