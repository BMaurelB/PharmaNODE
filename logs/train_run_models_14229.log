/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib
  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so
  Reason: tried: '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/read_tacro.py:159: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  df = df.applymap(lambda x: str(x).replace(",", ".") if isinstance(x, str) else x)
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/read_tacro.py:267: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1744320385493/work/torch/csrc/utils/tensor_new.cpp:281.)
  'auc_be': torch.tensor(auc_be),
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/read_tacro.py:391: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  df = df.applymap(lambda x: str(x).replace(",", ".") if isinstance(x, str) else x)
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/read_tacro.py:391: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  df = df.applymap(lambda x: str(x).replace(",", ".") if isinstance(x, str) else x)
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py
run_models.py --niters 5000 -n 200 -s 40 -l 10 --dataset PK_Tacro --latent-ode --noise-weight 0.01 --max-t 5. --seed 50 --experiment 14229
Experiment 14229
Epoch 0010 [Test seq (cond on sampled tp)] | Loss 6903.745117 | Likelihood -7296.572754 | KL fp 1.8544 | FP STD 0.7982|
KL coef: 0.0
Train loss (one batch): 7854.29443359375
Train CE loss (one batch): 0.0
Test MSE (raw): 1.4601
Test MSE (smoothed with alpha=0.01): 1.4601
New best smoothed test MSE: 1.4601. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 1.8477
Test MSE group_1: 1.3398
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 2.8014
train MSE group_1: 1.3278
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0020 [Test seq (cond on sampled tp)] | Loss 1992.939941 | Likelihood -2110.118896 | KL fp 3.6101 | FP STD 0.5508|
KL coef: 0.09561792499119559
Train loss (one batch): 2720.689208984375
Train CE loss (one batch): 0.0
Test MSE (raw): 0.4228
Test MSE (smoothed with alpha=0.01): 1.4497
New best smoothed test MSE: 1.4497. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.3958
Test MSE group_1: 0.4311
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.3203
train MSE group_1: 0.6453
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0030 [Test seq (cond on sampled tp)] | Loss 2155.353516 | Likelihood -2309.729736 | KL fp 2.9111 | FP STD 0.5317|
KL coef: 0.18209306240276923
Train loss (one batch): 2214.876953125
Train CE loss (one batch): 0.0
Test MSE (raw): 0.4627
Test MSE (smoothed with alpha=0.01): 1.4398
New best smoothed test MSE: 1.4398. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.6218
Test MSE group_1: 0.4133
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.7936
train MSE group_1: 0.3849
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0040 [Test seq (cond on sampled tp)] | Loss 1766.227783 | Likelihood -1827.843018 | KL fp 2.9751 | FP STD 0.4331|
KL coef: 0.2602996266117198
Train loss (one batch): 1736.82080078125
Train CE loss (one batch): 0.0
Test MSE (raw): 0.3663
Test MSE (smoothed with alpha=0.01): 1.4291
New best smoothed test MSE: 1.4291. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.4910
Test MSE group_1: 0.3276
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.6543
train MSE group_1: 0.3173
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0050 [Test seq (cond on sampled tp)] | Loss 1611.250610 | Likelihood -1648.274170 | KL fp 3.6309 | FP STD 0.3224|
KL coef: 0.3310282414303197
Train loss (one batch): 1599.226806640625
Train CE loss (one batch): 0.0
Test MSE (raw): 0.3304
Test MSE (smoothed with alpha=0.01): 1.4181
New best smoothed test MSE: 1.4181. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.4641
Test MSE group_1: 0.2889
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.6012
train MSE group_1: 0.2662
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0060 [Test seq (cond on sampled tp)] | Loss 1269.890259 | Likelihood -1311.175659 | KL fp 3.3080 | FP STD 0.3694|
KL coef: 0.39499393286246365
Train loss (one batch): 1224.34326171875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.2630
Test MSE (smoothed with alpha=0.01): 1.4065
New best smoothed test MSE: 1.4065. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.3204
Test MSE group_1: 0.2452
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.4596
train MSE group_1: 0.1979
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0070 [Test seq (cond on sampled tp)] | Loss 800.510010 | Likelihood -834.167603 | KL fp 3.3202 | FP STD 0.3282|
KL coef: 0.4528433576092388
Train loss (one batch): 641.9347534179688
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1676
Test MSE (smoothed with alpha=0.01): 1.3941
New best smoothed test MSE: 1.3941. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1804
Test MSE group_1: 0.1636
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1920
train MSE group_1: 0.1261
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0080 [Test seq (cond on sampled tp)] | Loss 731.555542 | Likelihood -747.402161 | KL fp 4.1390 | FP STD 0.2476|
KL coef: 0.505161340399793
Train loss (one batch): 561.501708984375
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1502
Test MSE (smoothed with alpha=0.01): 1.3817
New best smoothed test MSE: 1.3817. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.2359
Test MSE group_1: 0.1236
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1485
train MSE group_1: 0.1111
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0090 [Test seq (cond on sampled tp)] | Loss 724.887695 | Likelihood -736.325623 | KL fp 4.0280 | FP STD 0.1834|
KL coef: 0.5524767862361895
Train loss (one batch): 509.07525634765625
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1480
Test MSE (smoothed with alpha=0.01): 1.3694
New best smoothed test MSE: 1.3694. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1613
Test MSE group_1: 0.1439
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1242
train MSE group_1: 0.0984
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0100 [Test seq (cond on sampled tp)] | Loss 630.044617 | Likelihood -637.873840 | KL fp 4.4140 | FP STD 0.1596|
KL coef: 0.5952680273216762
Train loss (one batch): 481.53350830078125
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1283
Test MSE (smoothed with alpha=0.01): 1.3570
New best smoothed test MSE: 1.3570. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1652
Test MSE group_1: 0.1169
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1394
train MSE group_1: 0.0891
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0110 [Test seq (cond on sampled tp)] | Loss 604.824768 | Likelihood -614.447388 | KL fp 4.4237 | FP STD 0.1861|
KL coef: 0.6339676587267709
Train loss (one batch): 451.3055114746094
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1236
Test MSE (smoothed with alpha=0.01): 1.3446
New best smoothed test MSE: 1.3446. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1716
Test MSE group_1: 0.1087
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1231
train MSE group_1: 0.0910
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0120 [Test seq (cond on sampled tp)] | Loss 582.409485 | Likelihood -593.292358 | KL fp 4.5423 | FP STD 0.1512|
KL coef: 0.6689669116789861
Train loss (one batch): 449.9571228027344
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1194
Test MSE (smoothed with alpha=0.01): 1.3324
New best smoothed test MSE: 1.3324. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1520
Test MSE group_1: 0.1093
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1160
train MSE group_1: 0.0854
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0130 [Test seq (cond on sampled tp)] | Loss 587.660767 | Likelihood -594.826050 | KL fp 4.3060 | FP STD 0.1520|
KL coef: 0.7006196086876687
Train loss (one batch): 439.4501647949219
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1197
Test MSE (smoothed with alpha=0.01): 1.3202
New best smoothed test MSE: 1.3202. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1368
Test MSE group_1: 0.1144
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1177
train MSE group_1: 0.0831
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0140 [Test seq (cond on sampled tp)] | Loss 550.191223 | Likelihood -561.778198 | KL fp 4.6366 | FP STD 0.1283|
KL coef: 0.729245740488006
Train loss (one batch): 419.9650573730469
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1131
Test MSE (smoothed with alpha=0.01): 1.3082
New best smoothed test MSE: 1.3082. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1408
Test MSE group_1: 0.1045
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0985
train MSE group_1: 0.0825
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0150 [Test seq (cond on sampled tp)] | Loss 545.828735 | Likelihood -552.575073 | KL fp 4.4449 | FP STD 0.1419|
KL coef: 0.7551347009650705
Train loss (one batch): 405.4073791503906
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1113
Test MSE (smoothed with alpha=0.01): 1.2962
New best smoothed test MSE: 1.2962. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1326
Test MSE group_1: 0.1046
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1004
train MSE group_1: 0.0802
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0160 [Test seq (cond on sampled tp)] | Loss 530.523132 | Likelihood -536.885986 | KL fp 4.3073 | FP STD 0.1637|
KL coef: 0.7785482127611391
Train loss (one batch): 403.37200927734375
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1081
Test MSE (smoothed with alpha=0.01): 1.2843
New best smoothed test MSE: 1.2843. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1217
Test MSE group_1: 0.1039
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0814
train MSE group_1: 0.0823
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 14229
Epoch 0170 [Test seq (cond on sampled tp)] | Loss 640.290161 | Likelihood -663.195557 | KL fp 3.8230 | FP STD 0.2229|
KL coef: 0.7997229731425107
Train loss (one batch): 391.1026611328125
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1334
Test MSE (smoothed with alpha=0.01): 1.2728
New best smoothed test MSE: 1.2728. Saving best model to experiments/experiment_14229_best.ckpt
Test MSE group_0: 0.1219
Test MSE group_1: 0.1369
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0850
train MSE group_1: 0.0797
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Couldn't import umap
Sampling dataset of 200 training examples
############## ['1841', '1651', '11451', '2221', '11751', '3711', '1811', '11231', '1711', '2441', '3541', '3850', '2421', '3750', '1331', '1611', '2331', '11711', '1941', '150', '3521', '3211', '31041', '3721', '3151', '2411', '3131', '3651', '11131', '11031', '350', '750', '450', '11051', '1211', '11111', '3611', '250', '1511', '3650', '11721', '3831', '1650', '2321', '1231', '11741', '650', '31051', '1821', '3821', '11121', '11021', '2311', '1250', '11241', '3931', '11151', '3050', '1350', '2231', '2511', '1550', '3411', '1731', '11621', '31021', '3331', '2111', '11141', '1111', '3141', '1950', '11041', '1221', '3351', '3811', '3250', '3751', '1121', '1831', '2250', '11341', '1151', '2451', '3551', '2531', '2121', '2550', '2450', '1551', '1441', '2151', '1850', '31011', '3631', '1241', '1050', '11331', '1721', '2350', '1311', '3311', '11421', '1911', '3321', '3450', '3731', '950', '11531', '2521', '11541', '1450', '3511', '11611', '31031', '1750', '2950', '1421', '1150', '2750', '850', '2150', '1541', '11011', '2650', '2141', '11251', '11411', '2551', '3741', '4250', '1131', '1321', '1521', '3950', '3851', '11441', '2211', '11731', '4050', '3531', '1531', '2050', '3421', '1141', '2131', '3121', '1641', '3911', '2251', '1741', '3221']
177
TensorBoard logs will be saved to: experiments/runs/14229
Traceback (most recent call last):
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py", line 288, in <module>
    train_res["loss"].backward()
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/autograd/function.py", line 292, in apply
    def apply(self, *args):

KeyboardInterrupt
