/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib
  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/image.so
  Reason: tried: '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/NODE_test/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py
run_models.py --niters 5000 -n 200 -s 40 -l 10 --dataset PK_Tacro --latent-ode --noise-weight 0.01 --max-t 5. --seed 1 --experiment 29556
Experiment 29556
Epoch 0010 [Test seq (cond on sampled tp)] | Loss 2385.410645 | Likelihood -2498.266602 | KL fp 2.9831 | FP STD 0.3818|
KL coef: 0.0
Train loss (one batch): 2420.1826171875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.5004
Test MSE (smoothed with alpha=0.01): 0.5004
New best smoothed test MSE: 0.5004. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.5312
Test MSE group_1: 0.4696
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.5410
train MSE group_1: 0.4320
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0020 [Test seq (cond on sampled tp)] | Loss 1388.609863 | Likelihood -1438.847900 | KL fp 3.8536 | FP STD 0.2472|
KL coef: 0.09561792499119559
Train loss (one batch): 1458.6929931640625
Train CE loss (one batch): 0.0
Test MSE (raw): 0.2885
Test MSE (smoothed with alpha=0.01): 0.4983
New best smoothed test MSE: 0.4983. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.3251
Test MSE group_1: 0.2519
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.3272
train MSE group_1: 0.2625
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0030 [Test seq (cond on sampled tp)] | Loss 1075.788452 | Likelihood -1157.849121 | KL fp 5.5355 | FP STD 0.2909|
KL coef: 0.18209306240276923
Train loss (one batch): 1278.8031005859375
Train CE loss (one batch): 0.0
Test MSE (raw): 0.2323
Test MSE (smoothed with alpha=0.01): 0.4956
New best smoothed test MSE: 0.4956. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.1777
Test MSE group_1: 0.2869
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.2037
train MSE group_1: 0.3317
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0040 [Test seq (cond on sampled tp)] | Loss 1002.490479 | Likelihood -1048.946899 | KL fp 4.4656 | FP STD 0.2892|
KL coef: 0.2602996266117198
Train loss (one batch): 1153.0458984375
Train CE loss (one batch): 0.0
Test MSE (raw): 0.2105
Test MSE (smoothed with alpha=0.01): 0.4928
New best smoothed test MSE: 0.4928. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.2081
Test MSE group_1: 0.2129
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.2187
train MSE group_1: 0.2606
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0050 [Test seq (cond on sampled tp)] | Loss 649.691040 | Likelihood -669.477722 | KL fp 5.4402 | FP STD 0.1631|
KL coef: 0.3310282414303197
Train loss (one batch): 764.7770385742188
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1346
Test MSE (smoothed with alpha=0.01): 0.4892
New best smoothed test MSE: 0.4892. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.1222
Test MSE group_1: 0.1471
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.1381
train MSE group_1: 0.1760
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0060 [Test seq (cond on sampled tp)] | Loss 424.109100 | Likelihood -456.321472 | KL fp 5.5424 | FP STD 0.2010|
KL coef: 0.39499393286246365
Train loss (one batch): 574.5680541992188
Train CE loss (one batch): 0.0
Test MSE (raw): 0.0920
Test MSE (smoothed with alpha=0.01): 0.4852
New best smoothed test MSE: 0.4852. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.0769
Test MSE group_1: 0.1071
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0757
train MSE group_1: 0.1603
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Experiment 29556
Epoch 0070 [Test seq (cond on sampled tp)] | Loss 504.053802 | Likelihood -538.196899 | KL fp 4.5493 | FP STD 0.2321|
KL coef: 0.4528433576092388
Train loss (one batch): 437.7791748046875
Train CE loss (one batch): 0.0
Test MSE (raw): 0.1084
Test MSE (smoothed with alpha=0.01): 0.4814
New best smoothed test MSE: 0.4814. Saving best model to experiments/experiment_29556_best.ckpt
Test MSE group_0: 0.0843
Test MSE group_1: 0.1324
Test MSE group_2: nan
Test MSE group_3: nan
Poisson likelihood: 0.0
CE loss: 0.0
train MSE group_0: 0.0698
train MSE group_1: 0.1081
train MSE group_2: nan
train MSE group_3: nan
CE loss (TEST): 0.0
Couldn't import umap
Sampling dataset of 200 training examples
############## ['163', '164', '166', '167', '168', '169', '170', '172', '173', '174', '175', '176', '177', '178', '180', '181', '182', '183', '184', '185', '187', '188', '189', '190', '191', '192', '193', '195', '196', '198', '199', '200']
160
TensorBoard logs will be saved to: experiments/runs/29556
Traceback (most recent call last):
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/run_models.py", line 288, in <module>
    train_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/base_models.py", line 261, in compute_all_losses
    pred_y, info = self.get_reconstruction(batch_dict["tp_to_predict"], 
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/latent_ode.py", line 98, in get_reconstruction
    sol_y = self.diffeq_solver(first_point_enc_aug, time_steps_to_predict)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/benjaminmaurel/Documents/Training_Sanofi/notebooks_hands_on/latent_ode/lib/diffeq_solver.py", line 40, in forward
    pred_y = odeint(self.ode_func, first_point, time_steps_to_predict, 
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py", line 80, in odeint
    solution = solver.integrate(t)
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py", line 34, in integrate
    solution[i] = self._advance(t[i])
                  ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py", line 246, in _advance
    self.rk_state = self._adaptive_step(self.rk_state)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py", line 311, in _adaptive_step
    y1, f1, y1_error, k = _runge_kutta_step(self.func, y0, f0, t0, dt, t1, tableau=self.tableau)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/NODE_test/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py", line 67, in _runge_kutta_step
    k = torch.empty(*f0.shape, len(tableau.alpha) + 1, dtype=y0.dtype, device=y0.device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
